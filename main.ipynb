{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series\n",
    "\n",
    "Name: Koh June Wen\n",
    "\n",
    "Admin Number: 2112956\n",
    "\n",
    "Class: DAAAFT2A04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df.drop(columns=df.columns[-2:], inplace=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")\n",
    "df = df.pivot(index=['Date', 'T', 'RH'], columns='Gas', values='Value')\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index('Date', inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.drop(columns=test.columns[-2:], inplace=True)\n",
    "test['Date'] = pd.to_datetime(test['Date'], format=\"%d/%m/%Y\")\n",
    "test['Value'] = np.nan\n",
    "test = test.pivot(index=['Date', 'T', 'RH'], columns='Gas', values='Value')\n",
    "test.reset_index(inplace=True)\n",
    "test.set_index('Date', inplace=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.lineplot(data=df, x='Date', y='CO', label='CO')\n",
    "sns.lineplot(data=df, x='Date', y='HC', label='HC')\n",
    "sns.lineplot(data=df, x='Date', y='NO2', label='NO2')\n",
    "sns.lineplot(data=df, x='Date', y='O3', label='O3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_change(values):\n",
    "    previous_values = values.iloc[:-1]\n",
    "    last_value = values.iloc[-1]\n",
    "\n",
    "    percent_change = (last_value - np.mean(previous_values)) / np.mean(previous_values)\n",
    "\n",
    "    return percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 2, figsize=(20, 10))\n",
    "\n",
    "df_pc_plot = df[['Date']]\n",
    "df_pc_plot[['CO', 'HC', 'NO2', 'O3']] = df[['CO', 'HC', 'NO2', 'O3']].rolling(window=30).aggregate(percentage_change)\n",
    "\n",
    "# CO\n",
    "ax_CO = sns.lineplot(data=df, x='Date', y='CO', ax=ax[0, 0]).set(title='Original')\n",
    "ax_CO_pc = sns.lineplot(data=df_pc_plot, x='Date', y='CO', ax=ax[0, 1]).set(title='Percentage Change')\n",
    "\n",
    "# HC\n",
    "ax_HC = sns.lineplot(data=df, x='Date', y='HC', ax=ax[1, 0])\n",
    "ax_HC_pc = sns.lineplot(data=df_pc_plot, x='Date', y='HC', ax=ax[1, 1])\n",
    "\n",
    "# NO2\n",
    "ax_NO2 = sns.lineplot(data=df, x='Date', y='NO2', ax=ax[2, 0])\n",
    "ax_NO2_pc = sns.lineplot(data=df_pc_plot, x='Date', y='NO2', ax=ax[2, 1])\n",
    "\n",
    "# O3\n",
    "ax_O3 = sns.lineplot(data=df, x='Date', y='O3', ax=ax[3, 0])\n",
    "ax_O3_pc = sns.lineplot(data=df_pc_plot, x='Date', y='O3', ax=ax[3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of data\n",
    "Cleaning the data makes the RMSE in the competition worse than not cleaning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[df['T'] > 0]\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(20, 10))\n",
    "# df_temp.reset_index()\n",
    "sns.lineplot(data=df_temp, x='Date', y='T', ax=ax[0])\n",
    "sns.lineplot(data=df_temp, x='Date', y='RH', ax=ax[1])\n",
    "sns.lineplot(data=df_temp, x='Date', y='CO', ax=ax[2])\n",
    "sns.lineplot(data=df_temp, x='Date', y='HC', ax=ax[2])\n",
    "sns.lineplot(data=df_temp, x='Date', y='NO2', ax=ax[2])\n",
    "sns.lineplot(data=df_temp, x='Date', y='O3', ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity of Time Series Data\n",
    "- Moving Average (Visual) - pd.rolling()\n",
    "- Augmented Dickey-Fuller Test (Statistical) - adfuller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "\n",
    "def timeSeriesStationaryInfo(series, window):\n",
    "\n",
    "    # Plot Rolling Statistics\n",
    "    movingAverage = series.rolling(window).mean()\n",
    "    movingStd = series.rolling(window).std()\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    orig = plt.plot(series, label='Original')\n",
    "    ma = plt.plot(movingAverage, label='Moving Average')\n",
    "    mstd = plt.plot(movingStd, label='Moving Standard Deviation')\n",
    "    plt.title('Checking stationary of time series data by comparing original data with moving average and standard deviation')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Perform Dickey-Fuller Test\n",
    "    print('Results from Dickey-Fuller Test')\n",
    "    dftest = adfuller(series, autolag='AIC') # Find out abt AIC\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[f'Critical Value ({key})'] = value\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_temp_series = df_temp['T']\n",
    "stationarity_T_temp = timeSeriesStationaryInfo(T_temp_series, 30)\n",
    "stationarity_T_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative Humidity (RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH_temp_series = df_temp['RH']\n",
    "stationarity_RH_temp = timeSeriesStationaryInfo(RH_temp_series, 30)\n",
    "stationarity_RH_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_temp_series = df_temp['CO']\n",
    "stationarity_CO_temp = timeSeriesStationaryInfo(CO_temp_series, 30)\n",
    "stationarity_CO_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_temp_series = df_temp['HC']\n",
    "stationarity_HC_temp = timeSeriesStationaryInfo(HC_temp_series, 30)\n",
    "stationarity_HC_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO2_temp_series = df_temp['NO2']\n",
    "stationarity_NO2_temp = timeSeriesStationaryInfo(NO2_temp_series, 30)\n",
    "stationarity_NO2_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O3_temp_series = df_temp['O3']\n",
    "stationarity_O3_temp = timeSeriesStationaryInfo(O3_temp_series, 30)\n",
    "stationarity_O3_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature (T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_series = df[['T']]\n",
    "stationarity_T = timeSeriesStationaryInfo(T_series, 30)\n",
    "stationarity_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative Humidity (RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH_series = df['RH']\n",
    "stationarity_RH = timeSeriesStationaryInfo(RH_series, 30)\n",
    "stationarity_RH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_series = df['CO']\n",
    "stationarity_CO = timeSeriesStationaryInfo(V_series, 30)\n",
    "stationarity_CO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_series = df['HC']\n",
    "stationarity_HC = timeSeriesStationaryInfo(V_series, 30)\n",
    "stationarity_HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_series = df['NO2']\n",
    "stationarity_NO2 = timeSeriesStationaryInfo(V_series, 30)\n",
    "stationarity_NO2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_series = df['O3']\n",
    "stationarity_O3 = timeSeriesStationaryInfo(V_series, 30)\n",
    "stationarity_O3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Decomposition\n",
    "Purposes:\n",
    "1. Visualising the components of the time series\n",
    "2. Seasonal adjustment\n",
    "\n",
    "`Multiplicative approach` - when the standard deviation of the time series data changes with time\\\n",
    "`Additive approach` - when the standard deviation remains constant\\\n",
    "If LOG(<em>value</em> / <em>value-1</em>) of all values in the dataframe has a normal distribution, the time series model is multiplicatiive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompose_T_mul = seasonal_decompose(df['T'], model='multiplicative')\n",
    "decompose_T = seasonal_decompose(df['T'], model='additive')\n",
    "decompose_RH = seasonal_decompose(df['RH'], model='additive')\n",
    "decompose_CO = seasonal_decompose(df['CO'], model='additive')\n",
    "decompose_HC = seasonal_decompose(df['HC'], model='additive')\n",
    "decompose_NO2 = seasonal_decompose(df['NO2'], model='additive')\n",
    "decompose_O3 = seasonal_decompose(df['O3'], model='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_NO2 = decompose_T.seasonal\n",
    "seasonal_NO2[seasonal_NO2 == seasonal_NO2[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "decompose_T.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "decompose_RH.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "decompose_CO.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "decompose_HC.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "decompose_NO2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "decompose_O3.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for seasonality\n",
    "Presence of seasonality in a time series model will be proven if a periodogram graph has an obvious spike in the y value while the surround values are relatively flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_f, T_den = periodogram(df['T'], 328)\n",
    "plt.semilogy(T_f, T_den)\n",
    "plt.ylim([1e-1, 1e2])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RH_f, RH_den = periodogram(df['RH'], 328)\n",
    "plt.semilogy(RH_f, RH_den)\n",
    "plt.ylim([1e-1, 1e2])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_f, CO_den = periodogram(df['CO'], 328)\n",
    "plt.semilogy(CO_f, CO_den)\n",
    "plt.ylim([1e1, 1e4])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_f, HC_den = periodogram(df['HC'], 328)\n",
    "plt.semilogy(HC_f, HC_den)\n",
    "plt.ylim([1e1, 1e4])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO2_f, NO2_den = periodogram(df['NO2'], 328)\n",
    "plt.semilogy(NO2_f, NO2_den)\n",
    "plt.ylim([1e1, 1e4])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O3_f, O3_den = periodogram(df['O3'], 328)\n",
    "plt.semilogy(O3_f, O3_den)\n",
    "plt.ylim([1e1, 1e4])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "maxlag = 30\n",
    "variables=df.columns  \n",
    "matrix = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "for col in matrix.columns:\n",
    "    for row in matrix.index:\n",
    "        test_result = grangercausalitytests(df[[row, col]], maxlag=maxlag, verbose=False)            \n",
    "        p_values = [round(test_result[i+1][0]['ssr_chi2test'][1],4) for i in range(maxlag)] # Chi-square test - test for association between 2 variables       \n",
    "        min_p_value = np.min(p_values)\n",
    "        matrix.loc[row, col] = min_p_value\n",
    "matrix.columns = [var + '_x' for var in variables]\n",
    "matrix.index = [var + '_y' for var in variables]\n",
    "print(matrix)\n",
    "\n",
    "# From the result, each column represents a predictor x of each variable and each row\n",
    "# represents the response y and the p-value of each pair of variabble are shown in the\n",
    "# matrix\n",
    "\n",
    "# E.g. Take the value 0.0012 (in row 3, column 4), it refers that HC_x is causal to CO_y\n",
    "# and hence, we can reject the null hypothesis\n",
    "\n",
    "rej_null_count = matrix[matrix < 0.05].count().sum()\n",
    "print(f\"\\n{rej_null_count / (len(df.columns) ** 2 - len(df.columns)) * 100}% of the comparisons are less than 0.05. This suggests that most of the variables are interchangably causing each other.\")\n",
    "print(f\"This makes this system of multi time series a good candidate for using VAR models to forecast.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cointegration Test\n",
    "This helps to establish the presence of a statistically significant connection between two or more series.\\\n",
    "When two or more time series are cointegrated, it means that they have a long run, statistically significant relationship.\\\n",
    "`How it works`: When you have two or more time series, and there exists a linear combination of them that has an `order of integration` (the number of differencing required to make a non-stationary time series stationary) less than that of the individual series, then the collection of series is said to be cointegrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def cointegration_test(df, alpha=0.05): \n",
    "    out = coint_johansen(df,-1,5)\n",
    "    d = {'0.90':0, '0.95':1, '0.99':2}\n",
    "    traces = out.lr1\n",
    "    cvts = out.cvt[:, d[str(1-alpha)]]\n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Summary\n",
    "    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n",
    "    for col, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)\n",
    "\n",
    "cointegration_test(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making time series data stationary\n",
    "Purpose: It can be easier to model. Statistical modeling methods assume or require the time series to be stationary\\\n",
    "\\\n",
    "Ways to convert non-stationary to stationary:\n",
    "- Log transforming of the data (If the time series is a multiplicative model)\n",
    "- Taking the square root of the data\n",
    "- Taking the cube root\n",
    "- Proportional change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adfuller_test(series, signif=0.05, name='', verbose=False):\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n",
    "    p_value = output['pvalue'] \n",
    "    def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "    # Print Summary\n",
    "    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n",
    "    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "    print(f' Significance Level    = {signif}')\n",
    "    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "    for key,val in r[4].items():\n",
    "        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "    if p_value <= signif:\n",
    "        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "        print(f\" => Series is Stationary.\")\n",
    "    else:\n",
    "        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "        print(f\" => Series is Non-Stationary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_diff = df_temp.diff().dropna()\n",
    "\n",
    "for name, column in df_temp_diff.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')\n",
    "\n",
    "# all the series are already stationary so there is no need to differentiate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df.diff().dropna()\n",
    "for name, column in df_diff.iteritems():\n",
    "    adfuller_test(column, name=column.name)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "`AIC`: penalizes complex models less, meaning that it may put more emphasis on model performance on the training dataset, and, in turn, select more complex models.\\\n",
    "`BIC`: penalizes the model more for its complexity, meaning that more complex models will have a worse (larger) score and will, in turn, be less likely to be selected.\\\n",
    "`Endogenous variables`: values that are determined by other variables in the system (Dependent variable)\\\n",
    "`Exogenous variables`: a variable that is not affected by other variables in the system (Independent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import  SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA, ARIMAResults\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from statsmodels.tsa.api import VAR, VARMAX\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=3, test_size=30)\n",
    "\n",
    "train_df, test_df = [], []\n",
    "\n",
    "for train_i, test_i in tss.split(df):\n",
    "    train_df.append(df.iloc[train_i])\n",
    "    test_df.append(df.iloc[test_i])\n",
    "\n",
    "train_df.append(df)\n",
    "test_df.append(test)\n",
    "\n",
    "train_df_diff, test_df_diff = [], []\n",
    "\n",
    "for train_i, test_i in tss.split(df_diff):\n",
    "    train_df_diff.append(df_diff.iloc[train_i])\n",
    "    test_df_diff.append(df_diff.iloc[test_i])\n",
    "\n",
    "train_df_diff.append(df_diff)\n",
    "test_df_diff.append(test[['T', 'RH']].diff().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ValueWarning\n",
    "# warnings.simplefilter('ignore', ValueWarning)\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR\n",
    "Can be used when 2 or more time series influence each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimising the number of lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"AIC\": [], \"BIC\": [], \"FPE\": [], \"HQIC\": []}\n",
    "\n",
    "v = 3 # 0 - 1st validation, 1 - 2nd validation, 2 - 3rd validation, 3 - final test\n",
    "\n",
    "exog_df = train_df[v].iloc[:, :2]\n",
    "endog_df = train_df[v].iloc[:, 2:]\n",
    "\n",
    "# exog_df = df.iloc[:, :2]\n",
    "# endog_df = df.iloc[:, 2:]\n",
    "\n",
    "var_model = VAR(exog=exog_df, endog=endog_df)\n",
    "for i in range(1, 20):\n",
    "    result = var_model.fit(i)\n",
    "    results_dict[\"AIC\"].append(result.aic)\n",
    "    results_dict[\"BIC\"].append(result.bic)\n",
    "    results_dict[\"FPE\"].append(result.fpe)\n",
    "    results_dict[\"HQIC\"].append(result.hqic)\n",
    "    print(f\"Lag Order = {i}\")\n",
    "    print(f\"AIC : {result.aic}\")\n",
    "    print(f\"BIC : {result.bic}\")\n",
    "    print(f\"FPE : {result.fpe}\")\n",
    "    print(f\"HQIC : {result.hqic} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for k in tqdm(range(1, 20)):\n",
    "    rmse_arr = []\n",
    "    aic_arr = []\n",
    "    for vt in range(3):\n",
    "        exog_df = train_df[vt].iloc[:, :2]\n",
    "        endog_df = train_df[vt].iloc[:, 2:]\n",
    "        n = len(test_df[vt].index)\n",
    "        exog_future = test_df[vt][['T', 'RH']]\n",
    "\n",
    "        var_model = VAR(exog=exog_df, endog=endog_df)\n",
    "        result = var_model.fit(k)\n",
    "        var_lag_order = result.k_ar\n",
    "        forecast_input = endog_df.values[-var_lag_order:]\n",
    "        fc = result.forecast(y=forecast_input, steps=n, exog_future=exog_future)\n",
    "        fc_df = pd.DataFrame(fc, columns=endog_df.columns, index=test_df[vt].index)\n",
    "        fc_df_melt = pd.melt(fc_df, ignore_index=False)\n",
    "        test_df_melt = pd.melt(test_df[vt].drop(columns=['T', 'RH']), ignore_index=False)\n",
    "        rmse_arr.append(mean_squared_error(fc_df_melt['value'], test_df_melt['value']) ** 0.5)\n",
    "        aic_arr.append(result.aic)\n",
    "    scores.append([k, np.mean(aic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['k', 'aic', 'rmse'])\n",
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 20)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0,0].plot(x, results_dict['AIC'])\n",
    "ax[0,0].set_title('AIC')\n",
    "ax[0,1].plot(x, results_dict['BIC'])\n",
    "ax[0,1].set_title('BIC')\n",
    "ax[1,0].plot(x, results_dict['FPE'])\n",
    "ax[1,0].set_title('FPE')\n",
    "ax[1,1].plot(x, results_dict['HQIC'])\n",
    "ax[1,1].set_title('HQIC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model_fitted = var_model.fit(1)\n",
    "var_model_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for Serial Correlation of Residuals (Errors)\n",
    "Used to check if there is any leftover pattern in the residuals (errors).\\\n",
    "If there is any correlation left in the residuals, then, there is some pattern in the time series that is still left to be explained by the model.\\\n",
    "Checking for Serial Correlation is to ensure that the model is sufficiently able to explain the variances and patterns in the time series.\\\n",
    "\\\n",
    "The value can of this statistic can vary between 0 and 4.\\\n",
    "The closer it is to the value 2, then there is no significant serial correlation.\\\n",
    "The closer it is to the value 0, then there is a positive serial correlation.\\\n",
    "The closer it is to the value 4, then there is a negative serial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "out = durbin_watson(var_model_fitted.resid)\n",
    "\n",
    "def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "for col, val in zip(df.columns, out):\n",
    "    print(adjust(col), ':', round(val, 2))\n",
    "\n",
    "# As the values are extremely close to the value 2, there is no significant serial correlation in the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_lag_order = var_model_fitted.k_ar\n",
    "\n",
    "forecast_input = endog_df.values[-var_lag_order:]\n",
    "forecast_input\n",
    "\n",
    "endog_df.iloc[-var_lag_order:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(test_df[v].index)\n",
    "exog_future = test_df[v][['T', 'RH']]\n",
    "\n",
    "fc = var_model_fitted.forecast(y=forecast_input, steps=n, exog_future=exog_future)\n",
    "fc_df = pd.DataFrame(fc, columns=endog_df.columns, index=test_df[v].index)\n",
    "fc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=fc_df, x='Date', y='CO', label='CO')\n",
    "sns.lineplot(data=fc_df, x='Date', y='HC', label='HC')\n",
    "sns.lineplot(data=fc_df, x='Date', y='NO2', label='NO2')\n",
    "sns.lineplot(data=fc_df, x='Date', y='O3', label='O3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RMSE check validation\n",
    "pred_fc = pd.melt(fc_df, ignore_index=False)\n",
    "true_fc = pd.melt(test_df[v].drop(columns=['T', 'RH']), ignore_index=False)\n",
    "print(mean_squared_error(pred_fc['value'], true_fc['value']) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`First` validation check RMSE (No. Lags - `8`): 187.26582\\\n",
    "`Second` validation check RMSE (No. Lags - `8`): 188.50737\\\n",
    "`Third` validation check RMSE (No. Lags - `18`): 201.34537\\\n",
    "`Third` validation check RMSE (No. Lags - `8`): 177.59665\\\n",
    "Avg RMSE from validation checks: 184.45661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_df_submit = pd.melt(fc_df, ignore_index=False)\n",
    "fc_df_submit.reset_index(inplace=True)\n",
    "fc_df_submit.insert(0, 'id', fc_df_submit.index)\n",
    "fc_df_submit.drop(columns=['Date', 'Gas'], inplace=True)\n",
    "fc_df_submit.to_csv('VAR_predictions.csv', index=False)\n",
    "\n",
    "###  (No. Lags - 17) RMSE 195.91798 ###\n",
    "### (No. Lags - 8) RMSE 174.00740 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diffed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_diff_dict = {\"AIC\": [], \"BIC\": [], \"FPE\": [], \"HQIC\": []}\n",
    "\n",
    "v = 3\n",
    "\n",
    "exog_df_diff = train_df_diff[v].iloc[:, :2]\n",
    "endog_df_diff = train_df_diff[v].iloc[:, 2:]\n",
    "\n",
    "var_model_diff = VAR(exog=exog_df_diff, endog=endog_df_diff)\n",
    "for i in range(1, 20):\n",
    "    result = var_model_diff.fit(i)\n",
    "    results_diff_dict[\"AIC\"].append(result.aic)\n",
    "    results_diff_dict[\"BIC\"].append(result.bic)\n",
    "    results_diff_dict[\"FPE\"].append(result.fpe)\n",
    "    results_diff_dict[\"HQIC\"].append(result.hqic)\n",
    "    print(f\"Lag Order = {i}\")\n",
    "    print(f\"AIC : {result.aic}\")\n",
    "    print(f\"BIC : {result.bic}\")\n",
    "    print(f\"FPE : {result.fpe}\")\n",
    "    print(f\"HQIC : {result.hqic} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 20)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0,0].plot(x, results_diff_dict['AIC'])\n",
    "ax[0,0].set_title('AIC')\n",
    "ax[0,1].plot(x, results_diff_dict['BIC'])\n",
    "ax[0,1].set_title('BIC')\n",
    "ax[1,0].plot(x, results_diff_dict['FPE'])\n",
    "ax[1,0].set_title('FPE')\n",
    "ax[1,1].plot(x, results_diff_dict['HQIC'])\n",
    "ax[1,1].set_title('HQIC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_lags_orders_diff = var_model_diff.select_order(maxlags=19)\n",
    "var_lags_orders_diff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_model_diff_fitted = var_model_diff.fit(7, ic='aic')\n",
    "var_model_diff_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "out = durbin_watson(var_model_diff_fitted.resid)\n",
    "\n",
    "def adjust(val, length= 6): return str(val).ljust(length)\n",
    "\n",
    "for col, val in zip(df.columns, out):\n",
    "    print(adjust(col), ':', round(val, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_lag_order_diff = var_model_diff_fitted.k_ar\n",
    "\n",
    "forecast_input_diff = endog_df_diff.values[-var_lag_order_diff:]\n",
    "forecast_input_diff\n",
    "\n",
    "endog_df_diff.iloc[-var_lag_order_diff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_future_diff = test_df_diff[v][['T', 'RH']]\n",
    "n = len(exog_future_diff.index)\n",
    "\n",
    "fc_diff = var_model_diff_fitted.forecast(y=forecast_input_diff, steps=n, exog_future=exog_future_diff)\n",
    "fc_diff_df = pd.DataFrame(fc_diff, columns=endog_df_diff.columns, index=exog_future_diff.index)\n",
    "fc_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_undiff_df = fc_diff_df.cumsum() + df.iloc[-1]\n",
    "first_record = (fc_diff_df.iloc[0] + df.iloc[-1]).to_frame().reset_index()\n",
    "first_record.rename(columns={first_record.columns[1]: \"value\"}, inplace=True)\n",
    "first_record['Date'] = (pd.to_datetime(fc_undiff_df.index[0]) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "first_record = pd.pivot(first_record, index='Date', columns='Gas', values='value')\n",
    "fc_undiff_df = pd.concat([first_record, fc_undiff_df], axis=0)\n",
    "fc_undiff_df.drop(columns=['T', 'RH'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)\n",
    "sns.lineplot(data=fc_undiff_df, x='Date', y='CO', label='CO')\n",
    "sns.lineplot(data=fc_undiff_df, x='Date', y='HC', label='HC')\n",
    "sns.lineplot(data=fc_undiff_df, x='Date', y='NO2', label='NO2')\n",
    "sns.lineplot(data=fc_undiff_df, x='Date', y='O3', label='O3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RMSE check validation\n",
    "pred_fc = pd.melt(fc_diff_df, ignore_index=False)\n",
    "true_fc = pd.melt(test_df_diff[v].drop(columns=['T', 'RH']), ignore_index=False)\n",
    "print(mean_squared_error(pred_fc['value'], true_fc['value']) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`First` validation check RMSE (No. Lags - `7`): 179.54453\\\n",
    "`Second` validation check RMSE (No. Lags - `7`): 168.06703\\\n",
    "`Third` validation check RMSE (No. Lags - `7`): 173.83961\\\n",
    "Avg RMSE from validation checks: 173.81706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_df_submit = pd.melt(fc_undiff_df, ignore_index=False)\n",
    "fc_df_submit.reset_index(inplace=True)\n",
    "fc_df_submit.insert(0, 'id', fc_df_submit.index)\n",
    "fc_df_submit.drop(columns=['Date', 'Gas'], inplace=True)\n",
    "fc_df_submit.to_csv('VAR_predictions.csv', index=False)\n",
    "\n",
    "### RMSE 212.50707 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF & PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "acf_ = plot_acf(df['T'], ax=ax[0])\n",
    "pacf_ = plot_pacf(df['T'], ax=ax[1])\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "acf_ = plot_acf(df['RH'], ax=ax[0])\n",
    "pacf_ = plot_pacf(df['RH'], ax=ax[1])\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "acf_ = plot_acf(df['CO'], ax=ax[0])\n",
    "pacf_ = plot_pacf(df['CO'], ax=ax[1])\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "acf_ = plot_acf(df['HC'], ax=ax[0])\n",
    "pacf_ = plot_pacf(df['HC'], ax=ax[1])\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "df_NO2 = (df['NO2'] - df['NO2'].rolling(30).mean()).dropna()\n",
    "acf_ = plot_acf(df['NO2'], ax=ax[0])\n",
    "pacf_ = plot_pacf(df['NO2'], ax=ax[1])\n",
    "\n",
    "# acf_ = plot_acf(df_NO2, ax=ax[0])\n",
    "# pacf_ = plot_pacf(df_NO2, ax=ax[1])\n",
    "\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()\n",
    "\n",
    "## Shows a seasonal order of 8 for NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NO2_diff = df['NO2'].diff(8).dropna()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "acf_ = plot_acf(df_NO2_diff, lags=[8, 16,24,32,40,48,56,64], ax=ax[0])\n",
    "pacf_ = plot_pacf(df_NO2_diff, lags=[8, 16,24,32,40,48,56,64], ax=ax[1])\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 7), sharey=True)\n",
    "acf_ = plot_acf(df['O3'], ax=ax[0])\n",
    "pacf_ = plot_pacf(df['O3'], ax=ax[1])\n",
    "plt.ylim([-1.4, 1.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling Tuning\n",
    "Using AIC for comparison instead of BIC because AIC is better for modeling a predictive model while BIC is better for modeling an explanatory model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 3\n",
    "exog_df = train_df[v].iloc[:, :2]\n",
    "endog_df = train_df[v].iloc[:, 2:]\n",
    "\n",
    "n = len(test_df[v].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    aic_arr = []\n",
    "    bic_arr = []\n",
    "    for v in range(3):\n",
    "        exog_df = train_df[v].iloc[:, :2]\n",
    "        endog_df = train_df[v].iloc[:, 2:]\n",
    "        n = len(test_df[v].index)\n",
    "\n",
    "        arima_model = ARIMA(endog=endog_df['CO'], exog=exog_df, order=order)\n",
    "        arima_result = arima_model.fit()\n",
    "        fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "        rmse_arr.append(mean_squared_error(fc, test_df[v]['CO']) ** 0.5)\n",
    "        aic_arr.append(arima_result.aic)\n",
    "        bic_arr.append(arima_result.bic)\n",
    "    \n",
    "    scores.append([order[0], order[1], order[2], np.mean(aic_arr), np.mean(bic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic', 'rmse'])\n",
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['CO'], exog=exog_df, order=order)\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0], order[1], order[2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            for Q in range(1,3):\n",
    "                for D in range(3):\n",
    "                    for P in range(1,3):\n",
    "                        order_arr.append([[q,d,p], [Q,D,P,8]])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['CO'], exog=exog_df, order=order[0], seasonal_order=order[1])\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0][0], order[0][1], order[0][2], order[1][0], order[1][1], order[1][2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    aic_arr = []\n",
    "    bic_arr = []\n",
    "    for v in range(3):\n",
    "        exog_df = train_df[v].iloc[:, :2]\n",
    "        endog_df = train_df[v].iloc[:, 2:]\n",
    "        n = len(test_df[v].index)\n",
    "\n",
    "        arima_model = ARIMA(endog=endog_df['HC'], exog=exog_df, order=order)\n",
    "        arima_result = arima_model.fit()\n",
    "        fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "        rmse_arr.append(mean_squared_error(fc, test_df[v]['HC']) ** 0.5)\n",
    "        aic_arr.append(arima_result.aic)\n",
    "        bic_arr.append(arima_result.bic)\n",
    "    \n",
    "    scores.append([order[0], order[1], order[2], np.mean(aic_arr), np.mean(bic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic', 'rmse'])\n",
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))\n",
    "\n",
    "# no cross validation\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['HC'], exog=exog_df, order=order)\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0], order[1], order[2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['HC'], exog=exog_df, order=order)\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0], order[1], order[2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            for Q in range(1,3):\n",
    "                for D in range(3):\n",
    "                    for P in range(1,3):\n",
    "                        order_arr.append([[q,d,p], [Q,D,P,8]])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['HC'], exog=exog_df, order=order[0], seasonal_order=order[1])\n",
    "    try:\n",
    "        arima_result = arima_model.fit()\n",
    "    except: print(order)\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0][0], order[0][1], order[0][2], order[1][0], order[1][1], order[1][2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    aic_arr = []\n",
    "    bic_arr = []\n",
    "    for v in range(3):\n",
    "        exog_df = train_df[v].iloc[:, :2]\n",
    "        endog_df = train_df[v].iloc[:, 2:]\n",
    "        n = len(test_df[v].index)\n",
    "\n",
    "        arima_model = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=order)\n",
    "        arima_result = arima_model.fit()\n",
    "        fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "        rmse_arr.append(mean_squared_error(fc, test_df[v]['NO2']) ** 0.5)\n",
    "        aic_arr.append(arima_result.aic)\n",
    "        bic_arr.append(arima_result.bic)\n",
    "    \n",
    "    scores.append([order[0], order[1], order[2], np.mean(aic_arr), np.mean(bic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic', 'rmse'])\n",
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=order)\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0], order[1], order[2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            for Q in range(1,3):\n",
    "                for D in range(3):\n",
    "                    for P in range(1,3):\n",
    "                        order_arr.append([[q,d,p], [Q,D,P,7]])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    aic_arr = []\n",
    "    bic_arr = []\n",
    "    for v in range(3):\n",
    "        exog_df = train_df[v].iloc[:, :2]\n",
    "        endog_df = train_df[v].iloc[:, 2:]\n",
    "        n = len(test_df[v].index)\n",
    "\n",
    "        try:\n",
    "            arima_model = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=order[0], seasonal_order=order[1])\n",
    "            arima_result = arima_model.fit()\n",
    "            fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "            rmse_arr.append(mean_squared_error(fc, test_df[v]['NO2']) ** 0.5)\n",
    "            aic_arr.append(arima_result.aic)\n",
    "            bic_arr.append(arima_result.bic)\n",
    "        except: continue\n",
    "    \n",
    "    scores.append([order[0][0], order[0][1], order[0][2], order[1][0], order[1][1], order[1][2], np.mean(aic_arr), np.mean(bic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'aic', 'bic', 'rmse'])\n",
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            for Q in range(1,3):\n",
    "                for D in range(3):\n",
    "                    for P in range(1,3):\n",
    "                        order_arr.append([[q,d,p], [Q,D,P,8]])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=order[0], seasonal_order=order[1])\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0][0], order[0][1], order[0][2], order[1][0], order[1][1], order[1][2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    rmse_arr = []\n",
    "    aic_arr = []\n",
    "    bic_arr = []\n",
    "    for v in range(3):\n",
    "        exog_df = train_df[v].iloc[:, :2]\n",
    "        endog_df = train_df[v].iloc[:, 2:]\n",
    "        n = len(test_df[v].index)\n",
    "\n",
    "        arima_model = ARIMA(endog=endog_df['O3'], exog=exog_df, order=order)\n",
    "        arima_result = arima_model.fit()\n",
    "        fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "        rmse_arr.append(mean_squared_error(fc, test_df[v]['O3']) ** 0.5)\n",
    "        aic_arr.append(arima_result.aic)\n",
    "        bic_arr.append(arima_result.bic)\n",
    "    \n",
    "    scores.append([order[0], order[1], order[2], np.mean(aic_arr), np.mean(bic_arr), np.mean(rmse_arr)])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic', 'rmse'])\n",
    "print(\"rmse : \\n\", scores_df.sort_values(by='rmse', ascending=True).head(1))\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cross validation\n",
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            order_arr.append([q,d,p])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=order)\n",
    "    arima_result = arima_model.fit()\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0], order[1], order[2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "order_arr = []\n",
    "\n",
    "for q in range(1,3):\n",
    "    for d in range(3):\n",
    "        for p in range(1,3):\n",
    "            for Q in range(1,3):\n",
    "                for D in range(3):\n",
    "                    for P in range(1,3):\n",
    "                        order_arr.append([[q,d,p], [Q,D,P,8]])\n",
    "\n",
    "for order in tqdm(order_arr):\n",
    "    exog_df = train_df[v].iloc[:, :2]\n",
    "    endog_df = train_df[v].iloc[:, 2:]\n",
    "    n = len(test_df[v].index)\n",
    "\n",
    "    arima_model = ARIMA(endog=endog_df['O3'], exog=exog_df, order=order[0], seasonal_order=order[1])\n",
    "    try:\n",
    "        arima_result = arima_model.fit()\n",
    "    except:print(order)\n",
    "    fc = arima_result.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "    scores.append([order[0][0], order[0][1], order[0][2], order[1][0], order[1][1], order[1][2], arima_result.aic, arima_result.bic])\n",
    "\n",
    "scores_df = pd.DataFrame(scores, columns=['p', 'd', 'q', 'P', 'D', 'Q', 'aic', 'bic'])\n",
    "print(\"aic : \\n\", scores_df.sort_values(by='aic', ascending=True).head(1))\n",
    "print(\"bic : \\n\", scores_df.sort_values(by='bic', ascending=True).head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation (AIC) # with HC,NO2 seasonal order\n",
    "CO_order = (1,1,2)\n",
    "HC_order, HC_seasonal_order = (2,1,1), (2,2,2,8)\n",
    "NO2_order, NO2_seasonal_order = (2,1,1), (1,2,2,8)\n",
    "O3_order = (2,2,1)\n",
    "\n",
    "## validation (AIC) # with cross validation\n",
    "# CO_order = (2,1,1)\n",
    "# HC_order = (2,1,1)\n",
    "# NO2_order, NO2_seasonal_order = (1,0,2), (2,2,2,8)\n",
    "# O3_order = (2,1,1)\n",
    "\n",
    "## validation (RMSE) # with cross validation\n",
    "# CO_order = (2,0,1)\n",
    "# HC_order = (2,0,1)\n",
    "# NO2_order, NO2_seasonal_order = (1,0,1), (1,0,2,8)\n",
    "# O3_order = (2,0,2)\n",
    "\n",
    "## validation (RMSE) # with NO2 seasonal order\n",
    "# CO_order = (2,2,1)\n",
    "# HC_order = (1,1,2)\n",
    "# NO2_order, NO2_seasonal_order = (2,2,2), (2,1,2,8)\n",
    "# O3_order = (1,0,1)\n",
    "\n",
    "## validation (RMSE)\n",
    "# CO_order = (2,2,1)\n",
    "# HC_order = (1,1,2)\n",
    "# NO2_order = (2,2,2)\n",
    "# O3_order = (1,0,1)\n",
    "\n",
    "## validation (AIC)\n",
    "# CO_order = (2,1,1)\n",
    "# HC_order = (2,1,1)\n",
    "# NO2_order, NO2_seasonal_order = (2,1,1), (1,2,2,8)\n",
    "# O3_order = (2,1,1)\n",
    "\n",
    "## validation (AIC) # no cross validation | with NO2 seasonal order\n",
    "# CO_order = (1,1,2)\n",
    "# HC_order = (2,1,1)\n",
    "# NO2_order, NO2_seasonal_order = (2,1,1), (1,2,2,8)\n",
    "# O3_order = (1,1,2)\n",
    "\n",
    "## validation (AIC) # no cross validation | no No2 seasonal order\n",
    "# CO_order = (1,1,2)\n",
    "# HC_order = (2,1,1)\n",
    "# NO2_order = (2,1,1)\n",
    "# O3_order = (2,1,1)\n",
    "\n",
    "v = 3\n",
    "exog_df = train_df[v].iloc[:, :2]\n",
    "endog_df = train_df[v].iloc[:, 2:]\n",
    "\n",
    "n = len(test_df[v].index)\n",
    "\n",
    "arima_model_CO = ARIMA(endog=endog_df['CO'], exog=exog_df, order=CO_order)\n",
    "# arima_model_CO = ARIMA(endog=endog_df['CO'], exog=exog_df, order=CO_order, seasonal_order=CO_seasonal_order)\n",
    "arima_result_CO = arima_model_CO.fit()\n",
    "\n",
    "# arima_model_HC = ARIMA(endog=endog_df['HC'], exog=exog_df, order=HC_order)\n",
    "arima_model_HC = ARIMA(endog=endog_df['HC'], exog=exog_df, order=HC_order, seasonal_order=HC_seasonal_order)\n",
    "arima_result_HC = arima_model_HC.fit()\n",
    "\n",
    "# arima_model_NO2 = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=NO2_order)\n",
    "arima_model_NO2 = ARIMA(endog=endog_df['NO2'], exog=exog_df, order=NO2_order, seasonal_order=NO2_seasonal_order)\n",
    "arima_result_NO2 = arima_model_NO2.fit()\n",
    "\n",
    "arima_model_O3 = ARIMA(endog=endog_df['O3'], exog=exog_df, order=O3_order)\n",
    "# arima_model_O3 = ARIMA(endog=endog_df['O3'], exog=exog_df, order=O3_order, seasonal_order=O3_seasonal_order)\n",
    "arima_result_O3 = arima_model_O3.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Diagonstics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] = (14, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_CO.plot_diagnostics()\n",
    "plt.show()\n",
    "\n",
    "# From these plots we can observe that the residuals conform to normal distribution\n",
    "# The correlogram suggests that there is no auto correlation in the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_CO.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_HC.plot_diagnostics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_HC.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NO2\n",
    "Without adding a seasonal order for NO2, diagnostic plot and summary shows that the residuals are non-normal which means that the prediction intervals will not be accurate.\\\n",
    "Adding a season order decreases the Jarque-Bera (a metric to determine the normality) value significantly. However, the resdiuals are still non-normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_NO2.plot_diagnostics()\n",
    "plt.show()\n",
    "\n",
    "## the NO2 model is not optimised\n",
    "## Histogram does not fit a normal distribution\n",
    "## The residuals of the Q-Q graph is not following the straight line\n",
    "## Correlogram there is a significant correlation at value 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_NO2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_O3.plot_diagnostics()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_result_O3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_HC = arima_result_HC.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "fc_CO = arima_result_CO.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "fc_NO2 = arima_result_NO2.forecast(steps=n, exog=test_df[v][['T', 'RH']])\n",
    "fc_O3 = arima_result_O3.forecast(steps=n, exog=test_df[v][['T', 'RH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fc = pd.DataFrame(pd.concat([fc_CO, fc_HC, fc_NO2, fc_O3], axis=0, ignore_index=False))\n",
    "final_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(test_df[v].drop(columns=['T', 'RH']))['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE : {mean_squared_error(final_fc, pd.melt(test_df[v].drop(columns=['T', 'RH']))['value']) ** 0.5}\")\n",
    "\n",
    "### Using RMSE as determining metric ###\n",
    "# 166.\n",
    "\n",
    "### Using RMSE with seasonal order for NO2 ###\n",
    "# 163.57124\n",
    "\n",
    "### Using AIC as determining metric ###\n",
    "# 169.84430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_df = pd.concat([fc_CO, fc_HC, fc_NO2, fc_O3], axis=1)\n",
    "fc_df.columns = ['CO', 'HC', 'NO2', 'O3']\n",
    "fc_df.index.name = 'Date'\n",
    "sns.lineplot(data=fc_df, x='Date', y='CO', label='CO')\n",
    "sns.lineplot(data=fc_df, x='Date', y='HC', label='HC')\n",
    "sns.lineplot(data=fc_df, x='Date', y='NO2', label='NO2')\n",
    "sns.lineplot(data=fc_df, x='Date', y='O3', label='O3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_df_submit = pd.melt(fc_df, ignore_index=False)\n",
    "fc_df_submit.reset_index(inplace=True)\n",
    "fc_df_submit.insert(0, 'id', fc_df_submit.index)\n",
    "fc_df_submit.drop(columns=['Date', 'variable'], inplace=True)\n",
    "fc_df_submit.to_csv('ARIMA_indiv_predictions.csv', index=False)\n",
    "\n",
    "### RMSE 154.24407 ### NO2 no seasonal order AIC metric\n",
    "### RMSE 153.33767 ### NO2 with seasonal order AIC metric\n",
    "### RMSE 183.41228 ### NO2 with seasonal order RMSE metric\n",
    "### RMSE 153.53418 ### RMSE | cross validation | NO2 seasonal order\n",
    "### RMSE 176.88901 ### AIC | cross validation | NO2 seasonal order\n",
    "### RMSE 194.33847 ### AIC | HC,NO2 seasonal order\n",
    "\n",
    "# Using RMSE as gridsearch metric may have overfitted the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d5babd99a4df02ec48601645cc9db139875b0384e29e5b3b3c9a97142b6b19c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
